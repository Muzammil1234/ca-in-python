{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from os.path import join\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from utils import top_n_specific\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the spaCy's tokenizer and sentence maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "tokenizer = English().Defaults.create_tokenizer(nlp)\n",
    "\n",
    "sent = English()\n",
    "sent.add_pipe(nlp.create_pipe(\"sentencizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_DIR, \"output.json\")) as f:\n",
    "    raw = f.read()\n",
    "    unified = json.loads(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = pd.read_csv(\"provided_data/train-test-split.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train data only for statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_row_train = split.SET.str.lower() == \"train\"\n",
    "train = split[is_row_train]\n",
    "train_indices = (\n",
    "    train.ID.str.extract(\"(\\d+)\").squeeze().astype(int) - 1\n",
    ")  # -1 for 0-based indexing\n",
    "train_data = [unified[idx] for idx in train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the statistical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    \"num_essays\": 0,\n",
    "    \"num_maj_claim\": 0,\n",
    "    \"num_claims\": 0,\n",
    "    \"num_premises\": 0,\n",
    "    \"num_paras\": 0,\n",
    "    \"num_true_conf_bias\": 0,\n",
    "    \"num_false_conf_bias\": 0,\n",
    "    \"num_suff_paras\": 0,\n",
    "    \"num_insuff_paras\": 0,\n",
    "    \"num_tokens\": 0,\n",
    "    \"num_sentences\": 0,\n",
    "    \"avg_num_tokens_in_major_claim\": 0,\n",
    "    \"avg_num_tokens_in_claims\": 0,\n",
    "    \"avg_num_tokens_in_premises\": 0,\n",
    "    \"10_most_specific_words_major_claim\": 0,\n",
    "    \"10_most_specific_words_claims\": 0,\n",
    "    \"10_most_specific_words_premises\": 0,\n",
    "}\n",
    "\n",
    "counters = defaultdict(list)\n",
    "args = [\"major_claim\", \"claims\", \"premises\"]\n",
    "\n",
    "for essay in train_data:\n",
    "\n",
    "    # straight forward counts\n",
    "    stats[\"num_essays\"] += 1\n",
    "    stats[\"num_maj_claim\"] += len(essay[\"major_claim\"])\n",
    "    stats[\"num_claims\"] += len(essay[\"claims\"])\n",
    "    stats[\"num_premises\"] += len(essay[\"premises\"])\n",
    "    stats[\"num_paras\"] += len(essay[\"paragraphs\"])\n",
    "    stats[\"num_true_conf_bias\"] += essay[\"confirmation_bias\"]\n",
    "    stats[\"num_false_conf_bias\"] += not essay[\"confirmation_bias\"]\n",
    "\n",
    "    # inner loop for each paragraph\n",
    "    for i in range(len(essay[\"paragraphs\"])):\n",
    "        is_sufficient = essay[\"paragraphs\"][i][\"sufficient\"]\n",
    "        stats[\"num_suff_paras\"] += is_sufficient\n",
    "        stats[\"num_insuff_paras\"] += not is_sufficient\n",
    "\n",
    "    # using spaCy's tokenizer and sentence maker\n",
    "    stats[\"num_tokens\"] += len(tokenizer(essay[\"text\"]))\n",
    "    stats[\"num_sentences\"] += sum([1 for _ in sent(essay[\"text\"]).sents])\n",
    "\n",
    "    # loop over arguments to count average tokens per essay (later averaged again)\n",
    "    for arg in args:\n",
    "        num_tokens = 0\n",
    "        counter = defaultdict(int)\n",
    "        for element in essay[arg]:\n",
    "            tokens = tokenizer(element[\"text\"])\n",
    "            num_tokens += len(tokens)\n",
    "            for token in tokens:\n",
    "                tkn = token.text.lower()\n",
    "                contains_alpha = bool(re.match(\"[a-z]\", tkn))\n",
    "                # skip words that are stop words\n",
    "                if tkn not in STOP_WORDS and contains_alpha:\n",
    "                    counter[token.text] = element[\"text\"].count(token.text)\n",
    "        counters[arg].append(counter)\n",
    "        stats[f\"avg_num_tokens_in_{arg}\"] += num_tokens / len(essay[arg])\n",
    "\n",
    "else:\n",
    "\n",
    "    # average them over all essays\n",
    "    stats[\"avg_num_tokens_in_major_claim\"] /= stats[\"num_essays\"]\n",
    "    stats[\"avg_num_tokens_in_claims\"] /= stats[\"num_essays\"]\n",
    "    stats[\"avg_num_tokens_in_premises\"] /= stats[\"num_essays\"]\n",
    "\n",
    "    # separate argument counters (each is a list of dictionaries)\n",
    "    major_claim_wc = counters[\"major_claim\"]\n",
    "    claims_wc = counters[\"claims\"]\n",
    "    premises_wc = counters[\"premises\"]\n",
    "\n",
    "    # merge the list of dictionaries into one per argument for overall count\n",
    "    mj_cntr = Counter()\n",
    "    for d in major_claim_wc:\n",
    "        mj_cntr.update(d)\n",
    "\n",
    "    claims_cntr = Counter()\n",
    "    for d in claims_wc:\n",
    "        claims_cntr.update(d)\n",
    "\n",
    "    premises_cntr = Counter()\n",
    "    for d in premises_wc:\n",
    "        premises_cntr.update(d)\n",
    "\n",
    "    # calculate the top-10 specific words\n",
    "    results = []\n",
    "    for arg in args:\n",
    "        res = top_n_specific(\n",
    "            arg,\n",
    "            mj_cntr=mj_cntr,\n",
    "            claims_cntr=claims_cntr,\n",
    "            premises_cntr=premises_cntr,\n",
    "            n=10,\n",
    "        )\n",
    "        results.append(res)\n",
    "\n",
    "        stats[f\"10_most_specific_words_{arg}\"] = list(res)\n",
    "\n",
    "    # re-check no words are common in any two lists\n",
    "    for i, j in itertools.combinations(range(len(results)), 2):\n",
    "        num_common_elements = len(results[i].intersection(results[j]))\n",
    "        assert num_common_elements == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_essays = 322\n",
      "\n",
      "num_maj_claim = 598\n",
      "\n",
      "num_claims = 1202\n",
      "\n",
      "num_premises = 3023\n",
      "\n",
      "num_paras = 820\n",
      "\n",
      "num_true_conf_bias = 122\n",
      "\n",
      "num_false_conf_bias = 200\n",
      "\n",
      "num_suff_paras = 538\n",
      "\n",
      "num_insuff_paras = 282\n",
      "\n",
      "num_tokens = 119752\n",
      "\n",
      "num_sentences = 5531\n",
      "\n",
      "avg_num_tokens_in_major_claim = 14.817\n",
      "\n",
      "avg_num_tokens_in_claims = 15.149\n",
      "\n",
      "avg_num_tokens_in_premises = 18.398\n",
      "\n",
      "10_most_specific_words_major_claim = ['advantages', 'benefits', 'best', 'essential', 'government', 'live', 'lives', 'negative', 'prefer', 'technology']\n",
      "\n",
      "10_most_specific_words_claims = ['future', 'human', 'living', 'number', 'problems', 'provide', 'skills', 'social', 'things', 'university']\n",
      "\n",
      "10_most_specific_words_premises = ['countries', 'country', 'different', 'friends', 'high', 'like', 'lot', 'study', 'use', 'want']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in stats.items():\n",
    "    if isinstance(v, list):\n",
    "        print(k, \"=\", sorted(v))\n",
    "    elif isinstance(v, float):\n",
    "        print(k, \"=\", f\"{v:.3f}\")\n",
    "    else:\n",
    "        print(k, \"=\", v)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
